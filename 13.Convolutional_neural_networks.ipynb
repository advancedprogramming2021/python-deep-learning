{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络（Convolutional Neural Network，CNN）是一种专门用来处理具有类似网格结构数据的神经网络。例如时间序列数据（时间轴上有规律地采样形成的一维网格）和图像数据（二维的像素网格）。因此它被广泛用于图像识别、语音识别等各种场合，在图像识别的比赛中，基于深度学习的方法几乎都以 CNN 为基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 整体结构\n",
    "\n",
    "之前介绍的神经网络中，相邻层的所有神经元之间都有连接，这称为全连接（Fully Connected）层或 Affine 层。全连接层后面跟着激活函数 ReLU 层（或者Sigmoid 层）。这里堆叠了4 层“Affine-ReLU”组合，然后第 5 层是全连接层，最后由 Softmax 层输出最终分类结果。\n",
    "\n",
    "![img](images/chapter13/fully_connected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 中新增了Convolution 层和Pooling 层。典型 CNN 的层连接顺序是“Convolution - ReLU -（Pooling）”（Pooling 层有时会被省略）。\n",
    "\n",
    "![img](images/chapter13/CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 卷积层\n",
    "\n",
    "## 2.1 全连接层存在的问题\n",
    "\n",
    "输入数据的形状被全连接层“忽视”了。例如，向全连接层输入图像数据时，需要将 3 维图像数据（宽、高和通道数）拉平为 1 维数据。实际上，前面使用的 MNIST 数据集的例子中，输入图像就是 1 通道、高 28 像素、长 28 像素的（1, 28, 28）形状，但却被排成 1 列，以 784 个数据的形式输入到全连接层中。\n",
    "\n",
    "图像的 3 维形状中含有重要的空间信息。例如，空间上邻近的像素为相似的值、RBG的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，3 维形状中可能隐藏有值得提取的本质模式。但是，因为全连接层会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息。\n",
    "\n",
    "而卷积层可以保持数据形状不变。当输入数据是图像时，卷积层会以 3 维数据的形式接收输入数据，并同样以 3 维数据的形式输出至下一层。因此，在 CNN 中，可以正确理解图像等具有形状的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 中将卷积层的输出数据称为 **特征图**（**feature map**）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 卷积运算\n",
    "\n",
    "对于输入数据，卷积运算以一定间隔滑动卷积核（或称为滤波器）的窗口并应用。将各个位置上卷积核的元素和输入的对应元素相乘，然后再求和（有时将这个计算称为乘积累加运算）。然后，将这个结果保存到输出的对应位置。将这个过程在所有位置都进行一遍，就可以得到卷积运算的输出。如果将一个二维数据定义为 $I$，二维卷积核定义为 $K$，则\n",
    "\n",
    "$$ S(i,j) = (I *K)(i,j) = \\sum_m \\sum_n I(i+m,j+n)K(m,n)$$\n",
    "\n",
    "假设用（height, width）表示数据和卷积核的形状，则下图中输入数据尺寸是(5, 5)，输出数据尺寸是(3, 3)，卷积核尺寸是(3, 3)，其数值为\n",
    "\n",
    "$$ \\Bigg(\n",
    "   \\begin{matrix}\n",
    "   0 & 1 & 2 \\\\\n",
    "   2 & 2 & 0 \\\\\n",
    "   0 & 1 & 2\n",
    "  \\end{matrix} \\Bigg)\n",
    "$$\n",
    "\n",
    "![img](images/chapter13/numerical_no_padding_no_strides.gif)\n",
    "\n",
    "令 $i$ 为输入数据尺寸，$k$ 为卷积核尺寸，$o$ 为输出数据尺寸，则有关系：\n",
    "\n",
    "$$ o = (i - k) + 1 $$\n",
    "\n",
    "当卷积层数增加时，网络的空间维度最终会缩减到1×1，这种情况下增加的层就不可能进行有意义的卷积了。\n",
    "\n",
    "在全连接的神经网络中，除了权重参数，还存在偏置。CNN 中，卷积核的参数就对应之前的权重。并且，CNN 中也存在偏置，偏置被加到应用了卷积核的所有元素上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 填充（padding）\n",
    "\n",
    "在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（通常为 0），这称为**填充**（padding），是卷积运算中经常会用到的处理。在下图中，对大小为 (4, 4) 的输入数据应用了幅度为 1 的填充。通过填充，大小为 (4, 4) 的输入数据变成了 (6, 6) 的形状。然后应用大小为 (3, 3) 的卷积核，生成了大小为 (4, 4) 的输出数据。\n",
    "\n",
    "![img](images/chapter13/padding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令 $p$ 为填充幅度，则有关系\n",
    "\n",
    "$$ o = (i - k) + 2p + 1 $$\n",
    "\n",
    "下图中的示例中，$i=5, k =4, p =2$，因此 $o=6$\n",
    "\n",
    "![img](images/chapter13/arbitrary_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Padding\n",
    "\n",
    "一类特殊的填充作为称之为 same padding，即使得输出数据尺寸等于输入数据尺寸。令卷积核尺寸 $k$ 为奇数（$k = 2n+1$），填充幅度 $p = \\lfloor \\frac{k}{2} \\rfloor= n$，则有\n",
    "\n",
    "$$ o = (i - 2n - 1)+2n+1 = i $$\n",
    "\n",
    "下图中的示例中，$i=o=5, k = 3, p=1$\n",
    "\n",
    "![img](images/chapter13/same_padding_no_strides.gif)\n",
    "\n",
    "在这种情况下，只要硬件支持，网络就能包含任意多的卷积层，这是因为卷积运算不改变下一层的结构。然而，输入数据中靠近边界的部分相比于中间部分对于输出数据的影响更小。这可能会导致边界像素存在一定程度的欠表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Padding\n",
    "\n",
    "另一类特殊的填充作为称之为 full padding，即使卷积核与数据刚相交时开始做卷积，因此填充幅度 $p = k - 1$，\n",
    "\n",
    "$$o = (i - k)+2(k-1)+1 = i+k-1$$\n",
    "\n",
    "下图中的示例中，$i=5, k = 3, p=2$，因此 $o=6$\n",
    "![img](images/chapter13/full_padding_no_strides.gif)\n",
    "\n",
    "它进行了足够多的零填充，使得每个像素在每个方向上恰好被访问了 $k$ 次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 步幅\n",
    "\n",
    "应用卷积核的位置间隔称为**步幅**（stride）。之前的例子中步幅都是 1，如果将步幅设为 2，则如下图所示，应用卷积核的窗口的间隔变为 2 个元素。\n",
    "\n",
    "![img](images/chapter13/stride.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令 $i$ 为输入数据尺寸，$p$ 为填充幅度，$k$ 为卷积核尺寸，$s$ 为步幅大小，$o$ 为输出数据尺寸，则有：\n",
    "\n",
    "$$ o = \\lfloor \\frac{i + 2p -k}{s} \\rfloor + 1 $$\n",
    "\n",
    "下图中的示例中，$i=5, k=3, s=2, p=1$，因此 $o=3$\n",
    "\n",
    "![img](images/chapter13/padding_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 三维数据的卷积运算\n",
    "\n",
    "图像是三维数据，将其表示为多维数组时顺序为(channel, height, width)，例如通道数为 C、高度为 H、长度为 W 的数据的形状可以写成 $(C, H, W)$。在进行卷积运算时，除了高、宽方向之外还需要处理通道方向。通道方向上有多个特征图时，会按通道进行输入数据和卷积核的卷积运算，并将结果相加，从而得到输出。需要注意的是，输入数据和卷积核的通道数要为相同的值。\n",
    "\n",
    "![img](images/chapter13/3D_conv_0.png)\n",
    "\n",
    "这里以 3 通道的数据为例，输入数据尺寸是(3, 5, 5)，卷积核尺寸为(3, 3, 3)，填充幅度为0，步幅为1，则输出数据尺寸为(2, 2)。\n",
    "\n",
    "![img](images/chapter13/3D_conv_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分步计算顺序如下所示：\n",
    "\n",
    "![img](images/chapter13/3D_conv_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要在通道方向上也拥有多个卷积运算的输出，就需要用到多个卷积核。如下图所示，通过应用 $FN$ 个卷积核，输出特征图也生成了 $FN$ 个。如果将这 $FN$ 个特征图汇集在一起，就得到了形状为 $(FN, OH,OW)$ 的数据体。\n",
    "\n",
    "![img](images/chapter13/multi_channel_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进一步完善包含偏置加法运算的卷积运算，如下图所示。卷积核输出结果的形状是 $(FN, OH,OW)$ ，偏置的形状是 $(FN, 1, 1)$，这两个数据相加时，得益于 NumPy 的广播功能，按通道加上相同的偏置值。\n",
    "\n",
    "![img](images/chapter13/multi_channel_conv_with_bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 批处理\n",
    "\n",
    "之前的全连接神经网络的实现对应了批处理，通过批处理能够实现高效化的运算和学习时对应 mini-batch 的 SGD 算法。卷积运算也同样支持批处理。为此，需要将在各层间传递的数据保存为四维数据，按(batch_num, channel, height, width)的顺序保存数据。\n",
    "\n",
    "![img](images/chapter13/batch_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 卷积层的动机\n",
    "\n",
    "卷积运算通过三个重要思想来帮助改进深度学习系统：**稀疏连接**（sparse connectivity）、**参数共享**（parameter sharing）、**等变表示**（equivariant representations）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1 稀疏连接\n",
    "\n",
    "传统的神经网络的全连接层使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩阵中每一个单独的参数都描述了一个输入单元与一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。然而，卷积网络具有稀疏连接（也叫作稀疏权重（sparse weights））的特征。这是通过使核的大小远小于输入数据大小来达到的。\n",
    "\n",
    "例如，有 $m$ 个输入和 $n$ 个输出，那么全连接层的矩阵乘法需要 $m×n$ 个参数并且相应算法的时间复杂度为 $O(m×n)$。如果我们限制每一个输出拥有的连接数为 $k$，\n",
    "那么稀疏的连接方法只需要 $k×n$ 个参数以及 $O(k×n)$ 的运行时间。在很多实际应用中，只需保持 $k$ 比 $m$ 小几个数量级，就能在机器学习的任务中取得好的表现。\n",
    "\n",
    "![img](images/chapter13/sparse_connectivity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度卷积网络中，处在网络深层的单元可能与绝大部分输入是间接交互的，这允许网络可以通过只描述稀疏连接的基石来高效地描述多个变量的复杂交互。下图中，灰色区域凸显了 $g3$ 神经元以及它的**感受野**（receptive field）。\n",
    "\n",
    "![img](images/chapter13/receptive_field.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.2 参数共享\n",
    "\n",
    "参数共享是指在一个模型的多个函数中使用相同的参数。\n",
    "\n",
    "在传统的神经网络中，当计算一层的输出时，权重矩阵的每一个元素只使用一次，当它乘以输入的一个元素后就再也不会用到了。\n",
    "\n",
    "在卷积神经网络中，核的每一个元素都作用在输入的每一位置上。卷积运算中的参数共享保证了我们只需要学习一个参数集合，而不是对于每一位置都需要学习一个单独的参数集合。这虽然没有改变前向传播的运行时间（仍然是 $O(k×n)$），但它显著地把模型的存储需求降低至 $k$ 个参数，并且 $k$ 通常要比 $m$ 小很多个数量级。因此，卷积在存储需求和统计效率方面极大地优于稠密矩阵的乘法运算。\n",
    "\n",
    "下图中的上半部分，单独的黑色箭头表示在全连接模型中对权重矩阵的中间元素的使用。这个模型没有使用参数共享，所以参数只使用了一次。而在卷积模型中因为参数共享，这个单独的参数被用于所有的输入位置。\n",
    "\n",
    "![img](images/chapter13/parameter_sharing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.3 等变表示\n",
    "\n",
    "参数共享的特殊形式使得神经网络层具有对**平移等变**（equivariance）的性质。如果一个函数满足输入改变，输出也以同样的方式改变这一性质，我们就说它是等变（equivariant）的。特别的是，如果函数 $f(x)$ 与 $g(x)$ 满足 $f(g(x))＝g(f(x))$，我们就说 $f(x)$ 对于变换 $g$ 具有等变性。对于卷积来说，如果令 $g$ 是输入的任意平移函数，那么卷积函数对于 $g$ 具有等变性。\n",
    "\n",
    "例如，令 $I$ 表示图像在整数坐标上的亮度函数，$g$ 表示图像函数的变换函数使得 $I'＝g(I)$，其中图像函数 $I′$ 满足 $I′(x,y )＝I(x-1，y)$。这个函数把 $I$ 中的每个像素向右移动一个单位。如果我们先对 $I$ 进行这种变换然后进行卷积操作所得到的结果，与先对 $I$ 进行卷积然后再对输出使用平移函数 $g$ 得到的结果是一样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 池化层\n",
    "\n",
    "池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。例如，最大池化（Max Pooling）函数使用相邻矩形区域内的最大值。其它常用的池化函数包括相邻矩形区域内的平均值（Average Pooling）、L2范数以及基于距中心像素距离的加权平均函数。\n",
    "\n",
    "一般来说，池化的窗口大小会和步幅设定成相同的值。下图是按步幅 2 进行2 × 2 的最大池化时的处理顺序。\n",
    "\n",
    "![img](images/chapter13/max_pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 池化层的特征\n",
    "\n",
    "- 池化只是从目标区域中取最大值（或者平均值），所以不存在要学习的参数。\n",
    "\n",
    "\n",
    "- 经过池化运算，输入数据和输出数据的通道数不会发生变化。\n",
    "\n",
    "\n",
    "- 对微小的位置变化具有鲁棒性\n",
    "      不管采用什么样的池化函数，当输入做出少量平移时，经过池化函数后的大多数输出并不会发生改变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 卷积层和池化层的实现\n",
    "\n",
    "## 4.1 卷积层的实现\n",
    "\n",
    "如果正常实现卷积运算，需要重复多层的 for 循环语句，但是存在使用 for 语句处理 NumPy 数组效率低下的缺点。这里，我们实现卷积运算不使用 for 语句，而是使用 im2col 这个便利的函数进行简单的实现。\n",
    "\n",
    "**im2col**（image to column）函数将输入数据展开以适合卷积核（权重）。对三维的输入数据应用 im2col 后，数据被转换为二维矩阵，如下图所示。\n",
    "\n",
    "![img](images/chapter13/im2col_3D.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 im2col 展开输入数据后，只需将卷积层的卷积核（权重）纵向展开为 1 列，并计算这 2 个矩阵的乘积即可。\n",
    "\n",
    "![img](images/chapter13/trans_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进一步考虑 batch 大小，令输入数据的形状为 $(N, C, H, W)$，卷积核的形状为 $(FN, C, FH, FW)$，输出数据的形状为 $(N, FN, OH, OW)$。im2col 函数返回的二维数据形状为 $(N \\times OH \\times OW, C \\times FH \\times FW)$，卷积核被展开为形状为 $(C \\times FH \\times FW, FN)$ 的 2 维数组，然后进行矩阵乘法运算，最后要将二维输出数据转换为合适的形状。整个卷积运算流程如下图所示，\n",
    "\n",
    "![img](images/chapter13/im2col_4D.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 由(数量, 通道, 高, 宽)的四维数组构成的输入数据\n",
    "    filter_h : 卷积核的高\n",
    "    filter_w : 卷积核的长\n",
    "    stride : 步幅\n",
    "    pad : 填充\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2维数组\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, out_h, out_w, filter_h, filter_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, :, :, y, x] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 2, 3, 1, 4, 5).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在卷积核的应用区域重叠的情况下，使用 im2col 函数展开后，展开后的元素个数会多于原方块的元素个数。因此，使用 im2col 的实现存在比普通的实现消耗更多内存的缺点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来使用 im2col 来实现卷积层，这里我们将卷积层实现为名为 Convolution 的类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = (H + 2*self.pad - FH)// self.stride + 1\n",
    "        out_w = (W + 2*self.pad - FW)// self.stride + 1\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T # 展开卷积核\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward() 函数的实现中，最后会将输出数据转换为合适的形状。\n",
    "\n",
    "![img](images/chapter13/transpose.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上就是卷积层的前向传播 forward 处理的实现，通过使用 im2col 进行数据展开后，可以像实现全连接层一样来实现。在进行卷积层的反向传播时，必须进行im2col 的逆处理。具体的实现见 demo_code/layers.py 文件中的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 池化层的实现\n",
    "\n",
    "池化层的实现和卷积层相同，都使用 im2col 展开输入数据。不过，池化的情况下，在通道方向上是独立的，因此池化的应用区域按通道单独展开。\n",
    "\n",
    "![img](images/chapter13/pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "像这样展开之后，最大池化层只需对展开的矩阵求各行的最大值，并转换为合适的形状即可。\n",
    "\n",
    "![img](images/chapter13/pooling_implementation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大池化层的实现按下面 3 个阶段进行：\n",
    "\n",
    "- 展开输入数据\n",
    "- 求各行的最大值\n",
    "- 转换为合适的输出大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # 展开\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # 最大值\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 转换\n",
    "        out_h = (H - self.pool_h) // self.stride + 1\n",
    "        out_w = (W - self.pool_w) // self.stride + 1\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "池化层的 backward 处理可以参考 ReLU 层的实现中使用的 max 的反向传播，具体的实现见 demo_code/layers.py 文件中的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. CNN的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经实现了卷积层和池化层，现在来组合这些层，搭建进行手写数字识别的卷积神经网络。网络的构成是“Convolution - ReLU - Pooling - Affine -\n",
    "ReLU - Affine - Softmax”，我们将它实现为名为SimpleConvNet的类。\n",
    "\n",
    "![img](images/chapter13/CNN_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleConvNet 的初始化函数（\\_\\_init\\_\\_）参数如下：\n",
    "- input_dim―输入数据的维度：（通道，高，长）\n",
    "- conv_param―卷积层的超参数（字典）。字典的关键字如下：\n",
    "      filter_num―卷积核的数量\n",
    "      filter_size―卷积核的大小\n",
    "      stride―步幅\n",
    "      pad―填充\n",
    "- hidden_size―隐藏层（全连接）的神经元数量\n",
    "- output_size―输出层（全连接）的神经元数量\n",
    "- weitght_int_std―初始化时权重的标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    \"\"\"简单的ConvNet\n",
    "\n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 输入大小（MNIST的情况下为784）\n",
    "    hidden_size_list : 隐藏层的神经元数量的列表（e.g. [100, 100, 100]）\n",
    "    output_size : 输出大小（MNIST的情况下为10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 指定权重的标准差（e.g. 0.01）\n",
    "        指定'relu'或'he'的情况下设定“He的初始值”\n",
    "        指定'sigmoid'或'xavier'的情况下设定“Xavier的初始值”\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 初始化权重\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 生成层\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习所需的参数是第 1 层的卷积层和剩余两个全连接层的权重和偏置，这些参数在初始化后保存在实例变量的 params 字典中。\n",
    "\n",
    "然后，从最前面开始按顺序向有序字典（OrderedDict）的 layers 中添加层。只有最后的 SoftmaxWithLoss 层被添加到别的变量 last_layer 中。\n",
    "\n",
    "像这样初始化后，进行推理的 predict 方法和求损失函数值的 loss 方法就可以像下面这样实现。\n",
    "\n",
    "```python\n",
    "def predict(self, x):\n",
    "    for layer in self.layers.values():\n",
    "        x = layer.forward(x)\n",
    "    return x\n",
    "\n",
    "def loss(self, x, t):\n",
    "    y = self.predict(x)\n",
    "    return self.last_layer.forward(y, t)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是基于误差反向传播法求梯度的代码实现。参数的梯度通过误差反向传播算法求出，因为已经在各层正确实现了正向传播和反向传播的功能，所以这里只需要以合适的顺序调用即可。最后，把各个权重参数的梯度保存到 grads 字典中。\n",
    "\n",
    "```python\n",
    "def gradient(self, x, t):\n",
    "    # forward\n",
    "    self.loss(x, t)\n",
    "\n",
    "    # backward\n",
    "    dout = 1\n",
    "    dout = self.last_layer.backward(dout)\n",
    "\n",
    "    layers = list(self.layers.values())\n",
    "    layers.reverse()\n",
    "    for layer in layers:\n",
    "        dout = layer.backward(dout)\n",
    "\n",
    "    # 设定\n",
    "    grads = {}\n",
    "    grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "    grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "    grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "    return grads\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，使用这个 SimpleConvNet 网络在 MNIST 数据集进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading completed\n",
      "=== epoch:1, train acc:0.19, test acc:0.174 ===\n",
      "=== epoch:2, train acc:0.84, test acc:0.827 ===\n",
      "=== epoch:3, train acc:0.896, test acc:0.88 ===\n",
      "=== epoch:4, train acc:0.927, test acc:0.887 ===\n",
      "=== epoch:5, train acc:0.916, test acc:0.902 ===\n",
      "=== epoch:6, train acc:0.938, test acc:0.926 ===\n",
      "=== epoch:7, train acc:0.942, test acc:0.931 ===\n",
      "=== epoch:8, train acc:0.954, test acc:0.944 ===\n",
      "=== epoch:9, train acc:0.965, test acc:0.948 ===\n",
      "=== epoch:10, train acc:0.969, test acc:0.954 ===\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.949\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from demo_code.download import load_mnist\n",
    "from demo_code.simple_convnet import SimpleConvNet\n",
    "from demo_code.trainer import Trainer\n",
    "\n",
    "max_epochs = 10\n",
    "\n",
    "# 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist()\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "x_train = x_train[:, np.newaxis, :, :]\n",
    "x_test = x_test[:, np.newaxis, :, :]\n",
    "\n",
    "# 处理花费时间较长的情况下减少数据\n",
    "x_train, t_train = x_train[:6000], t_train[:6000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用 MNIST 数据集训练 SimpleConvNet 网络，训练数据的识别率为 99.82%，测试数据的识别率为 98.96% 左右（每次学习的识别精度都会发生一些误差）。测试数据的识别率大约为 99%，就小型网络来说，这是一个非常高的识别率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. CNN的可视化\n",
    "\n",
    "刚才我们对MNIST数据集进行了简单的CNN学习。当时，第 1 层的卷积层的权重的形状是(30, 1, 5, 5)，即 30 个大小为 5 × 5、通道为 1 的卷积核。这意味着卷积核可以可视化为单通道的 5 × 5 灰度图像。现在，我们将卷积层（第 1 层）的卷积核显示为图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_show(filters, nx=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.0, wspace=0.1)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 随机进行初始化的权重\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAACZCAYAAABXEYHGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWY0lEQVR4nO3deWxU5fcG8NPOTGdKp8t02lK2UkBscUFERIwLICKCotGoaMToPxA2TRRcIglGjEvEBYLBuECNwQUwcY+CggZxKy3UskPZWrBKWyrF7tPe7x/+bDqXvs9hxF+0vs/nL4bnvXdub+fO6TT39MQ5jiNEREQ2iv+nD4CIiOifwiJIRETWYhEkIiJrsQgSEZG1WASJiMhaLIJERGQtbyyLk5OTnczMTGOelJQEt29qaoL5kSNHzmh7x3Hi/vy3z+dzAoGAca3P54P7am9vh3lcXBzMte3r6uqqHcfpOJlpaWlOdna2cb12brVWF+3ctba2wrysrKzjeAOBgBMMBo1ra2pq4L7S09Nh3qtXL5ij76uISHFxcdS5DQaDTjgcNq7/9ddf4f60c5uWlgbzUCgE8z179kQdb48ePRy0z7a2Nri/5uZmmJ/GdWTMIpGItLW1dbz4MzIynJycHOP6+Hj8c3ZdXR3MKysrYd7Q0ADz9vb2mF4L2mvX68VvmR6PB+bo/VMk+rXg8Xgc9HwtLS1wXykpKTD3+/0wT0xMhHl5eXnUuc3IyHByc3ON63/55Re4P+06096jtPfkY8eORR3vn2IqgpmZmbJw4UJjPmrUKLj97t27Yf7ggw+e0fadBQIBGT58uDFHBUdEpL6+HuYJCQkw1y7OtWvXHnYfz6uvvmpcr53bSCQC8507d8Jce4FOnjy543iDwaDccMMNxrUFBQVwX5MmTYL5/PnzYT548GCYe73eqHMbDofl4YcfNq5fsmQJ3J928V1//fUwv+WWW2A+evToqONNS0uTadOmGdefOHEC7u/gwYMw37VrF8xREXW/TnJycmTTpk3G9T169IDPtW7dOpg/+eSTMC8uLoZ5fX39Ka+FRx991Lj+jTfegPvTihj64VBEZM6cOTC/7LLLOo7X6/VK7969jWsPHTqk7QvmqGCJiAwdOhTmM2fOjDq3ubm5UlRUZFy/aNEiuD/th7eff/4Z5toPKEuXLj3c1f/z16FERGQtFkEiIrIWiyAREVmLRZCIiKzFIkhERNaK6e5Qn88H71bq2bMn3F67K62xsRHm6O4f992Rfr9fBg4caFyv3f6r3WGXn58P82uuuQbma9eujXp84sQJ+fzzz43rBwwYAPeHvi8iIoMGDYL5iBEjYN6Z1+uFd8nNmDEDbj9v3jyYa8f6ySefwNytvr5eCgsLjbl2Z+yNN94Ic3SnrIhIXl4ezN3q6+tl8+bNxlw73sOHu7wJroPWvoOum+rq6lP2he6ELikpgc+1atUqmG/btg3m2nuGm9/vh3dFatctaq8QwedORL8js7OEhATp37+/Mde+z9p1dMUVV8Bce49027t3r4wbN86YV1RUwO2vuuoqmM+ePRvmycnJMF+6dGmX/89PgkREZC0WQSIishaLIBERWYtFkIiIrMUiSERE1mIRJCIia7EIEhGRtWLqE/T7/XL22Wcbc61PQxv9oeVoVIY7a21thSNytCkP2rgfbbSR1hPp9ttvv8n7779vzLUJGlovmjbu58ILL4R5Z6FQSG6++WZjrvWhaef2xx9/hLn21+TdsrOz4RQJrUdSO15tqoOWuzU3N0tZWZkx37dvH9w+KysL5lrPKZqK8fLLL5/yf2gEjjbpQJtuUltbC3PtOnRPg0lJSZEJEyYY12vnduTIkTDXeqW1ft7O8vLy5OuvvzbmK1asgNtrI8L2798P8379+sHcze/3w95ErYdSm8zz3HPPwVzrizThJ0EiIrIWiyAREVmLRZCIiKzFIkhERNZiESQiImuxCBIRkbVYBImIyFoxzxNEc+QqKyvh9loPDuo3EhHp1auXMXPPWEtMTJTzzz/fuN49f9BN6yNcv349zLWv1a2pqQn2AqK+MRGRDz/8EOYZGRkwv+iii2DeWXx8vAQCAWO+detWuL3W56fNmIt1zlkgEIDzH5ctWwa3Ly4uhnlzczPMY50nqM3oQ69rEb3vccyYMX95+3fffTfqcSQSkaqqKuN6bR5grD2fbtrr2t0neOLECfnss8+M64uKiuD+tH7d0tJSmI8fPx7mnTU0NMiWLVuM+RdffAG312Yfattr8/3c6uvrYY9vamoq3F7rL9bqi3buTfhJkIiIrMUiSERE1mIRJCIia7EIEhGRtVgEiYjIWiyCRERkLRZBIiKyVkx9giK4l6+xsRFuW15eDnNtHiHav/u4evbsKffdd59xfZ8+feBzLV++HOaFhYUw9/v9MHf3lnk8HklJSTGu//333+H+fD4fzLWZdlpvX2daH5s2r047dyUlJTD3eDww7wqaRanNTaupqYE56uUSEXnnnXdg7paamiqTJk0y5ldeeSXcfurUqTDXrsOjR48as7a2tqjHDQ0NsD8LzcMTEamoqIC59rpG39euOI4D+zrRNSiCz42IyDnnnAPzBQsWwLyzY8eOyZIlS4y5dh2sW7cO5keOHIH5wYMHYe6WnJwsY8eONeYTJ06E2xcUFMD822+/hbk2W9KEnwSJiMhaLIJERGQtFkEiIrIWiyAREVmLRZCIiKzFIkhERNZiESQiImvFaTP8ohbHxVWJyOH/v8M5I/0dx+kYdvgvP1aRbny83elYRXi8f7PudKwi3fh4u9OxinS/4/1TTEWQiIjov4S/DiUiImuxCBIRkbVYBImIyFosgkREZC0WQSIishaLIBERWYtFkIiIrBXTUN1wOOygAaStra1we2046fHjx2GemJhozBobG6WlpaVjwmZCQoITCASM6+vr6+Fztbe3w1wb5un14lPb2tpa3blx0+PxOGiAKBoEKiISDAZhnpqaCnN0rkRE9u/f33G8GRkZTk5OjnFtfDz+2Uobvnzs2DGYo4G+/5dHnVufz+egIcfuQbFusQ5uddMGw9bV1UUdbzgchuc3EonA/VVVVcFcu85Q73BbW5u0t7d3nJCkpCQnFAoZ12vDoFtaWmCuDbnVtq+trY06tykpKU5WVpZxvXYdnOl7nPa+09TUVN2pWR42cWtDyHv06HFGx6L5/fffT7nO0PnT3lO1objp6ekwT0hIgPm2bduqu2qWj6kI9uvXT9avX2/MtanLK1euPKN82LBhxsw9dTgQCMgll1xiXP/DDz/A59IuXq3IZWRkwLyysjLqLyv4fD7Jzc01rt+zZw/c3/Dhw2GOJpWLiOTl5cH8pptu6jjenJwcOOUZ/bAiIvLTTz/B/KWXXoK5Nnm+qKgo6tz6/X45//zzjet/++03uD/tjVEror1794b52rVro443JydHvvrqK+P62tpauD/t/K1evRrmqLC4C2goFJLZs2cb12vXmTa9/Nprr4V5eXk5zFetWhV1brOysuSFF14wrteuA20a+1tvvQXz77//Hua7d+8+7b+4MmLECJhffPHFMC8sLIS5VrQ2btwYdayBQAC+R2s/vI4cORLmd911F8zRBzQRkZycnC7PLX8dSkRE1mIRJCIia7EIEhGRtVgEiYjIWiyCRERkrZjuDvV6vRIOh425dkdlWVkZzLVb6ydMmGDMtm/fHvU4NTUVrh88eDB8rqamJphr0tLSYP7iiy9GPY6Li4O30mt3Rg0cOBDm6O5IEZE+ffrAvLP29nbY5vDss8/C7deuXQvzAwcOwPzss8+GuVtSUhK8Uxjd6Sryxx2QiHZ3aP/+/WHu5vF44OuntLQUbq/d9addp+juXne7SHt7O7zrT7sz9vbbb4e59lrR7h5dtWpV1OO0tDS54YYbjOu/+eYbuL/nn38e5rt27YJ5LEKhkIwbN86Yn3XWWXD7++67D+Zz586F+dixY2G+cePGqMeRSATeuazdha21gWnvYVrLiAk/CRIRkbVYBImIyFosgkREZC0WQSIishaLIBERWYtFkIiIrMUiSERE1oqpT7CxsVG2bdtmzO+55x64vdaf1LNnT5ijURoejyfqcTAYlCuuuMK4fsaMGfC5tNFEe/fuhbn21/HdfYJ9+/aF/XVoqoCIyHvvvQdzzZAhQ0577YEDB2TKlCnGfMOGDXB7bSSK9jrQjtXd61VTUyNvvvmmcb3Wv4Sme4iIVFZWwvzcc8+FeVfQX/DXXgsVFRUw175e1KPo7hNsbm6W/fv3w/0hy5Ytg3mvXr1gjnqBu1JdXS2vv/66MX/ttdfg9toEFG1kmfZaOHToUMe/09PT5c477zSuzc7Ohvuqrq6GuTYdZdq0aTCfPn161OO2tjapq6szrtdGpGn1QevH/au93fwkSERE1mIRJCIia7EIEhGRtVgEiYjIWiyCRERkLRZBIiKyFosgERFZK6Y+wQMHDsgdd9xhzHfs2AG3z8/Ph3lmZibMW1pajJnjOFGPtX6gfv36wedKSEiA+fHjx2GuzcZy8/l8kpWVZcw3b94Mt9d6vxYvXgzzyy+/HOadnTx5Ur788ktjPmrUKLi91t+E5iqK/DG3LBZtbW1wzpnWl6j1L40YMQLmsfYv1dfXw++39lrQXpvarEs0a7OmpibqcWZmpsyaNcu4Xpt9+Nhjj8H86NGjMHf322qOHj0qjz76qDGvqqqC22sz/Pr27QvzWOZ2BgIB+J750ksvwe3XrFkD8/POOw/mN910E8zd4uPjYe9ha2sr3L5zj2RXtNmS2rxBE34SJCIia7EIEhGRtVgEiYjIWiyCRERkLRZBIiKyFosgERFZi0WQiIisFVOfYFpamkyePNmYP/3003D7w4cPw3zPnj0wD4VCxszrjf5SampqZOXKlXB/SGJiIsy13jLU89eVHj16yEUXXWTMn3rqKbh9QUEBzDdt2gRz9ww+JDExEfYvDRgwAG4fDodh3tDQcNrHcjpCoZCMHz/emKP+UxH967ngggtgfvfdd8PcPcPu2LFjsAesuLgY7k/ra9R63dBr193DGQwGYY+pu3/XTetF0+b7zZkzB+aLFi2KeqzNvBs2bBjcnzbLUuvX1WbidVZXVwd740aOHAm3RzMpRfQezE8//RTmbj6fD/YA//rrr3B7bS7nu+++C/N9+/bB3ISfBImIyFosgkREZC0WQSIishaLIBERWYtFkIiIrMUiSERE1mIRJCIia8VpfTxRi+PiqkQEN/v9c/o7jtMxkPBffqwi3fh4u9OxivB4/2bd6VhFuvHxdqdjFel+x/unmIogERHRfwl/HUpERNZiESQiImuxCBIRkbVYBImIyFosgkREZC0WQSIishaLIBERWSumobrx8fGOx+Mx5lrPYVxcHMy1IZBa7jhOxxMEg0EnPT3duLa5uRnuq76+Huba9gkJCTBvaGio7ty4mZqa6pzJQErt3KDv2+nkNTU1HcebnJzsoMG42vDkQCAA88zMU/pZoyQnJ8N8586dUec2FAo5ffr0Ma5vbGyE+9OG7mrnXtt/bW1ttavpGF5I2sBn9DoSOXUAtVskEjFmVVVVcvLkyY7rLBAIOOj7kZqaCp8rLS0N5hptSG1JSUnUuQ0EAk5SUpJxvTYUV7uug8EgzP1+P8yPHj162teZ9n6rvS6PHz8Oc+17V1lZGXVuMzIynNzc3L98PNp1or1Htba2wnzv3r3VXTXLx1QEPR6PZGRkGHOtMGhfhHYSUO4+wenp6fLggw8a15eVlcHnKiwshPn+/fthrk0jLywsjKoU2dnZ8sorrxjXL168GO4PTcsW0V/QoVAI5gUFBR3HGw6HZf78+ca106dPh/vSzs2sWbNgPnr0aJgPHTo06tz26dNHVq9ebVy/c+dOuL8jR47AXJvkXlpaCvM1a9bE9Fc28vLyYD537lyYo8nxIn9MtjdZsGBB1OPk5GQ4Hf66666Dz3XjjTfCXCty2g+rqampUec2KSlJJk6caFz/wQcfwP3l5OTA/LLLLoP5WWedBfNHHnkk6jpzn+/O0A8rIvq50Sa1o/MkIvL4449Hndvc3FwpKir6y8ejXSfoBwIR/TodN25cl9cZfx1KRETWYhEkIiJrsQgSEZG1WASJiMhaLIJERGStmO4O1TQ0NMBcu9NLy2MZ+9TY2Cjbt2835uvWrYPbHzp0COao/UJE5LbbboO5++7Tn3/+WR577DHj+hMnTsD9XXvttTBHd/WKiOTn58O8oKCg498ejwfebTp+/Hi4L+1W5uHDh8Nca1lwi0Qi8HZw7e5Q7XuttWxod9mtWbMm6nG/fv3gnc2DBw+G+9POf3FxMcx37NhhzNzfu4aGBvnpp5+M67U7GCsrK2Het29fmGt3ebs1NjbCuxDj4/HnAu096Oqrr4b5hAkTYP7II4+c9vNp77dVVVUwf+aZZ2Cu3cX9+OOPRz2urq6W5cuXG9drLRlDhgyBOXo/F9Fb8Ez4SZCIiKzFIkhERNZiESQiImuxCBIRkbVYBImIyFosgkREZC0WQSIislZMfYLJyckyZswYY/7LL7/A7bUpE1pP0cmTJ42Zu6/v5MmTsmHDBuN6bdyPNs7n/vvvh/kDDzwA83nz5kU9DofDMnXqVOP6gwcPwv1pf91em+Ch9Z51FolE4MgZbXKANgooJSUF5rH0i4r8MR7no48+MubaaCGtp1TrT1qyZAnM3bKysuTee+815q+++irc/oknnoC51teIpmK4e3kjkYhUV1cb12/atAk+15YtW2Cu9Q7H2jM6aNAgef/99425u2fTTTterZdNG4nWWUtLi5SXlxvzrVu3wu21XuWLL74Y5lr/rFt5ebnMnDnTmKMRViIit956K8y177XW42nc7i9tRURE9B/AIkhERNZiESQiImuxCBIRkbVYBImIyFosgkREZC0WQSIislZMfYK5ublwXlRFRQXcvra2FuaBQADm7hl8nT355JNRj1tbW+GsMq2vbsqUKTBHfVwiIjU1NTB3S09Ph32CWt+hNletpKQE5p988gnMO0tNTYXzC4uKiuD2K1euhHnn2YVd0fr6ulqP5ilqPZjabEmtL/Ltt9+GuVtFRQXsQ9X6cdPS0mAeDodhjua+ufv2AoEA7DHV+ua0eYKoZ1FEn3nn5vf7ZdCgQcZc61XWzr3WZ6j1H7uhntj29na47e7du2G+aNEimGtfq5vX65Xs7GxjnpubC7f/+OOPz+h4Lr30Upib8JMgERFZi0WQiIisxSJIRETWYhEkIiJrsQgSEZG1WASJiMhaLIJERGSt2BquBPet5OXlwW212WB1dXUwR30x7llVfr8f9i8NHToUPtfkyZNhHgwGYa715bnFx8fDOXsTJ06E25eWlsJcm+uG5u25JSQkwD7LL7/8Em6v9VBqsx61Pje37Oxseeihh4y51r+6fv16mGvn9plnnoG5W3JysowdO9aYa9dRfn4+zLXevRUrVhgz90xPr9cLe9+0OZU+nw/mTU1NMNdmT7p7QLU5o36/H+6vb9++MEffNxGR7777Duad9e7dWxYuXGjMtd7effv2wVzrj9XmVrr16tVLHn74YWOuvefu2rUL5suWLYO5Vj9M+EmQiIisxSJIRETWYhEkIiJrsQgSEZG1WASJiMhaLIJERGQtFkEiIrJWHOr7O2VxXFyViOAmrn9Of8dxOhqW/uXHKtKNj7c7HasIj/dv1p2OVaQbH293OlaR7ne8f4qpCBIREf2X8NehRERkLRZBIiKyFosgERFZi0WQiIisxSJIRETWYhEkIiJrsQgSEZG1WASJiMhaLIJERGSt/wEamSc3Tl5JGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学习后的权重\n",
    "network.load_params(\"demo_code/params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图可以看出，学习前的滤波器是随机进行初始化的，没有规律可循。但学习后的滤波器变成了有规律的图像，有些滤波器对垂直方向上的边缘有响应，有些滤波器对水平方向上的边缘有响应。\n",
    "\n",
    "上面的结果是针对第 1 层的卷积层得出的。第 1 层的卷积层中提取了边缘或斑块等“低级”信息，那么在堆叠了多层的 CNN 中，各层中又会提取什么样的信息呢？根据深度学习的可视化相关的研究，随着层次加深，提取的信息也越来越抽象。\n",
    "\n",
    "下图展示了进行一般物体识别的 8 层 CNN。这个网络结构的名称是下一节要介绍的 AlexNet。AlexNet 网络结构堆叠了多层卷积层和池化层，最后经过全连接层输出结果。\n",
    "\n",
    "![img](images/chapter13/CNN_visual.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着卷积神经网络层次加深，提取的信息也愈加复杂、抽象。最开始的层对简单的边缘有响应，接下来的层对纹理有响应，再后面的层对更加复杂的物体部件有响应。也就是说，随着层次加深神经元从简单的形状向“高级”信息变化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
