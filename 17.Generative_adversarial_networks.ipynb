{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bd97c1",
   "metadata": {},
   "source": [
    "# 1. 生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3bc2ec",
   "metadata": {},
   "source": [
    "**生成模型**(Generative Model) 是一个广泛的机器学习领域，它是处理概率分布 $p(x)$ 的模型，其中 $x \\in R_n$。这些模型是在某些潜在的高维空间中的数据点上定义的。通俗的理解，生成模型就是一类通过向真实数据分布学习，以此来确定其参数的模型，使得所学习的模型分布与真实数据分布尽可能地一致。但由于被建模随机变量的高维度，使得模型学习十分困难。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02265202",
   "metadata": {},
   "source": [
    "生成模型的工作流程：\n",
    "\n",
    "1. 从一个已知分布（例如高斯分布或均匀分布）中随机采样样本；\n",
    "\n",
    "\n",
    "2. 将该采样的样本输入到生成模型；\n",
    "\n",
    "\n",
    "3. 生成模型根据真实分布反馈的信息不断更新自己的参数；\n",
    "\n",
    "\n",
    "4. 经过若干次迭代，最后通过训练得到一个能够生成与真实数据尽可能一致的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981b2c97",
   "metadata": {},
   "source": [
    "传统生成模型通常基于马尔可夫链、最大似然及近似推理，其代表模型有限制玻尔兹曼机(Restricted Boltzmann Machines, RBM)及其衍生模型如深度信念网络(Deep Belief Network， DBN)、深度波尔茨曼机(Deep Boltzmann Machines, DBM)、变分自动编码器(Variational Auto-Encoder, VAE)等，此类方法计算复杂且生成效果有限。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ce7dc",
   "metadata": {},
   "source": [
    "2014年， [Ian Goodfellow 等](https://arxiv.org/abs/1406.2661) 提出了基于博弈论的生成模型——**生成对抗网络**(Generative Adversarial Network, **GAN**)。该网络模型在生成图像数据方面的表现令人惊异，如今已经成为众多研究者的关注点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c301a186",
   "metadata": {},
   "source": [
    "除了图像合成，生成对抗网络在计算机视觉(CV)任务中还有很多的应用，如图像超分辨率、语义分割、图像编辑、图像修复、图像去噪、图像融合以及视频生成等。生成对抗网络在自然语言处理(NLP)中的应用也呈现日益增长的趋势， 例如：从文本生成图像、字体生成、对话生成、机器翻译、语音生成等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae586a6",
   "metadata": {},
   "source": [
    "# 2. 生成对抗网络(GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ca718",
   "metadata": {},
   "source": [
    "## 2.1 GAN模型\n",
    "\n",
    "受博弈论中二人零和博弈思想的启发，**GAN** 主要由**生成器**(Generator)和**判别器**(Discriminator)两个部分组成，**生成器**和**判别器**分别作为博弈的两方。其中，**生成器**的目的是生成接近真实的样本去骗过判别器， 而**判别器**是去区分真实的样本和生成的样本。通过对抗训练来不断的提高各自的能力，最终达到一个纳什均衡(Nash equilibrium)的状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3885b9f",
   "metadata": {},
   "source": [
    "- **生成器**$G$：它以一个随机向量（隐空间中的一个随机点）作为输入，并将其解码为一张生成图像。\n",
    "\n",
    "\n",
    "- **判别器**$D$：以一张图像（真实的或生成的均可）作为输入，并预测该图像是来自训练集还是由生成器创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab3569",
   "metadata": {},
   "source": [
    "![img](images/chapter17/GAN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb07848",
   "metadata": {},
   "source": [
    "> 对于生成器 $G$ 来说，通过随机噪声 $z$ 作为输入，生成器 $G$ 期望自己生成的样本尽可能地欺骗判别器 $D$，所以需要最大化判别概率 $D(G(z))$。因此，生成器 $G$ 的目标函数可以定义为最小化 $\\log(1-D(G(z)))$。\n",
    "\n",
    "$$ {\\min_G} \\; \\mathbb{E}_{z\\sim p_ {z}\\;(z)}[\\log(1-D(G(z)))] $$\n",
    "\n",
    "> 对于判别器 $D$，为了尽可能地区分真实样本和虚假的生成样本，它希望最小化判别概率 $D(G(z))$ 的同时，最大化判别概率 $D(x)$。因此，判别器 $D$ 的目标函数可以定义为最大化 $ \\log D(x) + \\log(1-D(G(z)))$。\n",
    " \n",
    "$$ {\\max_D}\\;\\mathbb{E}_{x\\sim p_ {\\rm data}\\;(x)}[\\log D(x)] + \\mathbb{E}_{z\\sim p_ {z}\\;(z)}[\\log(1-D(G(z)))] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463fff5b",
   "metadata": {},
   "source": [
    "其中 $P_{\\rm data}(x)$ 代表真实样本的概率分布，$P_{z}(z)$ 代表随机噪声的概率分布，$z$ 是服从高斯分布的随机噪声。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5f2a3",
   "metadata": {},
   "source": [
    "基于以上思想可以设计出 GAN 的总目标函数如下式所示：\n",
    "\n",
    "$$ {\\min_G} \\; {\\max_D}\\; V(D, G) = \\mathbb{E}_{x\\sim p_ {\\rm data}\\;(x)}[\\log D(x)] + \\mathbb{E}_{z\\sim p_ {\\rm z}\\;(z)}[\\log(1-D(G(z)))] \\tag{1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a926a4",
   "metadata": {},
   "source": [
    "对抗训练过程由两个神经网络交替进行：\n",
    "\n",
    "- 先训练 $D$：选取一批真实样本和一批隐变量，隐变量通过 $G$ 得到生成样本，保持 $G$ 权值不变，利用随机梯度上升法计算并更新 $D$ 网络的权值；\n",
    "\n",
    "\n",
    "- 随后训练 $G$：选取一批隐变量通过 $G$ 得到生成样本，保持 $D$ 权值不变，利用随机梯度下降法计算并更新 $G$ 网络的权值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c95b3b",
   "metadata": {},
   "source": [
    "在对抗训练的过程中，判别器 $D$ 判别真假样本的能力逐渐提高；而生成器 $G$ 为了欺骗判别器 $D$，生成样本逐渐趋近于真实样本，最终使整个模型生成质量较好的新数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49f57e",
   "metadata": {},
   "source": [
    "## 2.2 全局最优解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef903ca",
   "metadata": {},
   "source": [
    "令 $p_g(x)$ 为 $G(z)$ 生成样本的概率分布， $p_{\\rm data}(x)$ 为真实样本的概率分布，则式（1）可写成：\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "V(D, G) &= \\mathbb{E}_{x\\sim p_{\\rm data}\\;(x)}[\\log D(x)] + \\mathbb{E}_{x\\sim p_{g}\\;(x)}[\\log (1-D(x))]\\\\\n",
    "&= \\int_x p_{\\rm data}(x)\\log (D(x))dx + \\int_x p_g(x) \\log(1-D(x))dx\\\\\n",
    "&= \\int_x p_{\\rm data}(x)\\log (D(x)) + p_g(x) \\log(1-D(x))dx\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f26885",
   "metadata": {},
   "source": [
    "对于固定 $G$，最大化函数 $V(D,G)$ 有\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial D} \\int_x p_{\\rm data}(x)\\log (D(x)) + p_g(x) \\log(1-D(x))dx \\triangleq 0 $$\n",
    "\n",
    "$$ \\Rightarrow \\int_x p_{\\rm data}(x) \\frac{1}{D(x)} + p_g(x) \\frac{-1}{1-D(x)}dx \\triangleq 0 $$\n",
    "\n",
    "$$ \\Rightarrow p_{\\rm data}(x) \\frac{1}{D(x)} = p_g(x) \\frac{1}{1-D(x)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305915f7",
   "metadata": {},
   "source": [
    "函数 $V(D,G)$ 达到极大值时的 $D(x) = D^*_G(x)$，即\n",
    "$$ D^*_G(x) = \\frac{p_{\\rm data}(x)}{p_{\\rm data}(x) + p_g(x)} \\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86cf4a",
   "metadata": {},
   "source": [
    "将 $D^*_G(x)$ 带入 $V(D, G)$ ：\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "{\\min_G} \\; {\\max_D}\\; V(D, G) &= {\\min_G} \\; V(D^*_G, G) \\\\\n",
    "&= {\\min_G} \\; \\mathbb{E}_{x\\sim p_{\\rm data}\\;(x)}\\left[\\log \\frac{p_{\\rm data}(x)}{p_{\\rm data}(x) + p_g(x)}\\right ] + \\mathbb{E}_{x\\sim p_{g}\\;(x)}\\left[\\log \\frac{p_g(x)}{p_{\\rm data}(x) + p_g(x)}\\right]\\\\\n",
    "&= {\\min_G} \\; \\mathbb{E}_{x\\sim p_{\\rm data}\\;(x)}\\left[\\log \\frac{p_{\\rm data}(x)}{(p_{\\rm data}(x) + p_g(x))/2}\\cdot \\frac{1}{2}\\right ] + \\mathbb{E}_{x\\sim p_{g}\\;(x)}\\left[\\log \\frac{p_g(x)}{(p_{\\rm data}(x) + p_g(x))/ 2}\\cdot \\frac{1}{2}\\right]\\\\\n",
    "&= {\\min_G} \\; KL \\left[p_{\\rm data}(x) \\bigg|\\bigg| \\frac{p_{\\rm data}(x) + p_g(x)}{2}\\right] + KL \\left[p_g(x) \\bigg|\\bigg| \\frac{p_{\\rm data}(x) + p_g(x)}{2}\\right] - \\log 4\n",
    "\\end{aligned} \\tag{3} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360a354",
   "metadata": {},
   "source": [
    "上式（3）中的 KL 散度值总是大于等于0，只有在两个分布相同 $p_g(x) = p_{\\rm data}(x)$ 时，KL值等于0，此时上式取最小值 $-\\log4$。同时，可计算式（2） $D^*_G(x) = \\frac{1}{2}$，意味着 $D$ 至多以50%的概率随机猜测样本属于真实样本或生成样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d261b52",
   "metadata": {},
   "source": [
    "## 2.3 生成结果\n",
    "\n",
    "将采样的随机噪声通过多层感知机网络构建的生成器来生成手写体数字和人脸图像，如下图所示。最右边的一列显示了与相邻样本最近的训练样本，以证明生成模型没有记住训练集。\n",
    "\n",
    "![GAN](images/chapter17/GAN_result.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06db0f",
   "metadata": {},
   "source": [
    "## 2.4 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a9ee8",
   "metadata": {},
   "source": [
    "优点：\n",
    "\n",
    "- 不要求对数据预设分布，直接进行采样和推断，非常适用于无监督和半监督学习任务；\n",
    "\n",
    "\n",
    "- 各种类型的损失函数和约束条件都可以整合到 GAN 框架中，有利于针对不同任务设计出不同类型的损失函数和优化方法；\n",
    "\n",
    "\n",
    "- 可以和现有的卷积神经网络(CNN) 、循环神经网络(RNN)等深度网络结合使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd25861",
   "metadata": {},
   "source": [
    "缺点：\n",
    "\n",
    "\n",
    "- 在模型训练过程中，存在**模式崩溃**问题：生成器从具有多种模式的训练集中仅学习到单个或有限的模式，而错失对其它模式的学习，从而无法生成具有多样性的样本；\n",
    "\n",
    "\n",
    "- 使用随机向量作为生成器的输入缺乏语义和可操作性，无法控制模型生成具有指定特征的样本；\n",
    "\n",
    "\n",
    "- 实际应用中比较难以训练，训练过程中易出现梯度消失、训练不稳定、神经网络难以收敛等问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c60bd32",
   "metadata": {},
   "source": [
    "# 3. 改进的GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b866f5",
   "metadata": {},
   "source": [
    "对 GAN 模型结构进行改进可以划分为输入输出、生成器、判别器、模型的模块结构和模块结构的组合思想 5 个部分："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d2c54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa2a540a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1b69109",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa7c1cd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03b5ee8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05201d59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cfed304",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79317238",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01410d12",
   "metadata": {},
   "source": [
    "# 4. [DCGAN(Deep Convolutional GAN)](https://arxiv.org/abs/1511.06434)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75241c",
   "metadata": {},
   "source": [
    "DCGAN 的生成器和判别器都使用了卷积神经网络(CNN)来替代原始 GAN 中的多层感知机，以此生成更高分辨率的图像。生成器模型如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e175f",
   "metadata": {},
   "source": [
    "![DCGAN](images/chapter17/DCGAN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22049f7e",
   "metadata": {},
   "source": [
    "DCGAN特点：\n",
    "\n",
    "- 使用反卷积层（生成器）和带步长的卷积层（判别器）替换了池化层\n",
    "\n",
    "- 在生成器和判别器中均使用了 BN 层\n",
    "\n",
    "- 去掉了全连接层\n",
    "\n",
    "- 使用 ReLU 作为生成器的激活函数（输出层使用 Tanh 激活函数）\n",
    "\n",
    "- 使用 LeakyReLU 作为判别器的激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f03a7",
   "metadata": {},
   "source": [
    "![img](images/chapter17/DCGAN_result.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb657827",
   "metadata": {},
   "source": [
    "# 5. [pix2pix](https://arxiv.org/abs/1611.07004)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cce1f2",
   "metadata": {},
   "source": [
    "pix2pix 是将GAN应用于有监督的图像到图像翻译(image translation)的经典论文。该模型可以将输入图像作为条件，学习从输入图像到输出图像之间的映射，从而得到指定的输出图像。 ~~补充介绍风格迁移的其他应用（图像修补、老照片修复、图像去噪、卡通化）~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f2f24",
   "metadata": {},
   "source": [
    "![pix2pix](images/chapter17/pix2pix_result.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937cee1",
   "metadata": {},
   "source": [
    "以训练轮廓图像到真实图像的生成为例，pix2pix 模型训练流程示意图如下图所示。轮廓图像 $x$ 作为生成器 $G$ 的输入（随机噪声 $z$ 在图中并未画出）得到生成图像 $G(x)$，然后将 $G(x)$ 和 $x$ 通道拼接作为判别器 $D$ 的输入。另外，将真实图像 $y$ 和 $x$ 也进行通道拼接作为判别器 $D$ 的输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac3719",
   "metadata": {},
   "source": [
    "![pix2pix](images/chapter17/pix2pix.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f152d",
   "metadata": {},
   "source": [
    "其中，生成器 $G$ 的网络模型可以采用传统的Encoder-decoder结构，或是采用在图像分割领域应用非常广泛的U-Net网络模型结构，而后者的生成效果更好。\n",
    "\n",
    "![img](images/chapter17/pix2pix_G.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99a31d",
   "metadata": {},
   "source": [
    "pix2pix 模型的优化目标分为两部分，分别为：\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "\\mathcal L_{cGAN}(D, G) &= \\mathbb{E}_{x,y}[\\log D(x, y)] + \\mathbb{E}_{x,z}[\\log(1-D(x, G(x, z)))]\\\\\n",
    "\\mathcal L_{L1}(G) &= \\mathbb{E}_{x,y,z}[||y-G(x,z)||_1]\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01024fa7",
   "metadata": {},
   "source": [
    "整体目标函数为：\n",
    "\n",
    "$$ G^* = \\arg {\\min_G} \\; {\\max_D}\\; V(D, G) = \\mathcal L_{cGAN}(D, G) + \\lambda \\mathcal L_{L1}(G) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ac2e0f",
   "metadata": {},
   "source": [
    "[pix2pix在线互动Demo](https://affinelayer.com/pixsrv/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d030a8a",
   "metadata": {},
   "source": [
    "# 6. [CycleGAN](https://arxiv.org/abs/1703.10593)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b71e1d2",
   "metadata": {},
   "source": [
    "CycleGAN 是一种无监督生成对抗网络，它的主要思想是训练两对生成器-判别器模型以将图像从一个域转换为另一个域。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59018571",
   "metadata": {},
   "source": [
    "![CycleGAN_result](images/chapter17/CycleGAN_result.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775795b",
   "metadata": {},
   "source": [
    "CycleGAN 模型如下图所示，由两个生成器 $G $ 、$F$ 和两个判别器 $D_Y$、$D_X$ 组成，其中 $G:X\\rightarrow Y$，$F:Y\\rightarrow X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdbf1f2",
   "metadata": {},
   "source": [
    "![CycleGAN_result](images/chapter17/CycleGAN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b874de0",
   "metadata": {},
   "source": [
    "模型的损失函数由两部分组成：\n",
    "\n",
    "- Adversarial Loss，\n",
    "\n",
    "$$ \\mathcal L_{GAN}(G, D_Y, X, Y) = \\mathbb{E}_{y\\sim p_ {\\rm data}\\;(y)}[\\log D_Y(y)] + \\mathbb{E}_{x\\sim p_ {\\rm data}\\;(x)}[\\log(1-D_Y(G(x)))] $$\n",
    "$$ \\mathcal L_{GAN}(F, D_X, Y, X) = \\mathbb{E}_{x\\sim p_ {\\rm data}\\;(x)}[\\log D_X(x)] + \\mathbb{E}_{y\\sim p_ {\\rm data}\\;(y)}[\\log(1-D_X(F(y)))] $$\n",
    "\n",
    "- Cycle Consistency Loss，目的是确保转换后的风格在反转换后可以回到原始状态\n",
    "\n",
    "$$ \\mathcal L_{cyc}(G, F) = \\mathbb{E}_{x\\sim p_ {\\rm data}\\;(x)}\\left[||F(G(x))-x||_1 \\right] + \\mathbb{E}_{y\\sim p_ {\\rm data}\\;(y)}\\left[||G(F(y))-y||_1 \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6ef09",
   "metadata": {},
   "source": [
    "因此总损失函数为：\n",
    "\n",
    "$$ \\mathcal L(G, F, D_X, D_Y) = \\mathcal L_{GAN}(G, D_Y, X, Y) + \\mathcal L_{GAN}(F, D_X, Y, X) + \\lambda \\mathcal L_{cyc}(G, F) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73dd00",
   "metadata": {},
   "source": [
    "# 7. [WGAN(Wasserstein GAN)](https://arxiv.org/abs/1701.07875)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ed7b1",
   "metadata": {},
   "source": [
    "[Towards Principled Methods for Training Generative Adversarial Networks](https://arxiv.org/abs/1701.04862), [Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a0644",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb4263c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c334ec9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb290ef3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75c5f80d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d1931c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7f743a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7380b7c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
